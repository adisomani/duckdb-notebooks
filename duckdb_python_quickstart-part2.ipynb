{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB Python Quickstart - Part 2\n",
    "\n",
    "Welcome back to your DuckDB Python quickstart series! In [Part 1](https://motherduck.com/learn-more/duckdb-python-quickstart-part1/), you covered the essentials: getting DuckDB installed, making connections, executing basic SQL queries using the `.sql()` and `.execute()` methods, ingesting data directly from files, and leveraging the powerful Relational API for programmatic query building, including set operations and joins.\n",
    "\n",
    "In this second part, you'll explore the features that truly make DuckDB a first-class citizen in the Python data ecosystem. You'll see how DuckDB seamlessly integrates with popular libraries like Pandas, Apache Arrow, and Polars, and how you can extend DuckDB's functionality by writing your own functions in Python.\n",
    "\n",
    "Now you can pick up where you left off and see how DuckDB interacts with your existing Python data structures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with the Python Data Ecosystem: Pandas, Arrow, Polars\n",
    "\n",
    "This is where DuckDB really shines for data professionals living in the Python world. DuckDB is designed to work *with* your existing data structures, not just separate from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Pandas DataFrames\n",
    "\n",
    "Got a Pandas DataFrame loaded in memory? You can query it directly as if it were a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬─────────┐\n",
      "│ col1  │  col2   │\n",
      "│ int64 │ varchar │\n",
      "├───────┼─────────┤\n",
      "│     1 │ A       │\n",
      "│     4 │ A       │\n",
      "└───────┴─────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "# Create a sample Pandas DataFrame\n",
    "data = {'col1': [1, 2, 3, 4],\n",
    "        'col2': ['A', 'B', 'C', 'A']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Connect to DuckDB (in-memory for this example)\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "# Query the DataFrame using duckdb.sql() via the connection\n",
    "result_relation = con.sql(\"SELECT * FROM df WHERE col2 = 'A'\")\n",
    "result_relation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! DuckDB automatically recognizes the DataFrame variable `df` in your Python environment (when using a connection or the default global connection) and makes it available as if it were a table in the `FROM` clause. This is incredibly powerful for quickly querying, filtering, joining, or aggregating DataFrames using familiar SQL syntax, which can often be much faster than equivalent Pandas operations for certain types of queries, especially aggregates and complex joins on larger DataFrames.\n",
    "\n",
    "You can also query the DataFrame using the relational API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬─────────┐\n",
      "│ col1  │  col2   │\n",
      "│ int64 │ varchar │\n",
      "├───────┼─────────┤\n",
      "│     1 │ A       │\n",
      "│     4 │ A       │\n",
      "└───────┴─────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the DataFrame using the relational API via the connection\n",
    "(con.sql(\"FROM df\") # Start with the DataFrame as a relation\n",
    " .filter(\"col2 = 'A'\")\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Info: SQLAlchemy Integration**\n",
    "> \n",
    "> For more complex applications requiring an Object-Relational Mapper (ORM) or a standard database interface like SQLAlchemy, you can use the `duckdb-engine` package (`pip install duckdb-engine`). This provides a SQLAlchemy dialect that allows you to interact with DuckDB using the full power of SQLAlchemy, including querying DataFrames registered with the engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Results as Pandas DataFrames\n",
    "\n",
    "Going the other way is just as easy. Any `DuckDBPyRelation` can be converted into a Pandas DataFrame using `.df()` or `.fetchdf()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "           Country  Population\n",
      "0     Afghanistan     31056997\n",
      "1         Albania      3581655\n",
      "2         Algeria     32930091\n",
      "3  American Samoa        57794\n",
      "4         Andorra        71201\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to DuckDB (or reuse connection)\n",
    "con = duckdb.connect(database=':memory:')\n",
    "con.sql(\"INSTALL httpfs\")\n",
    "con.sql(\"LOAD httpfs\")\n",
    "\n",
    "# Query a file or table to get a relation\n",
    "population_relation = con.sql(\"SELECT Country, Population FROM read_csv_auto('https://bit.ly/3KoiZR0')\")\n",
    "\n",
    "# Convert the result relation to a Pandas DataFrame\n",
    "population_df = population_relation.df()\n",
    "\n",
    "print(type(population_df))\n",
    "\n",
    "print(population_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seamless back-and-forth between DuckDB relations and Pandas DataFrames removes a lot of the impedance mismatch you might face with other databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Apache Arrow and Polars\n",
    "\n",
    "DuckDB also has deep integration with Apache Arrow, the standard for in-memory columnar data. Arrow enables zero-copy data transfer between DuckDB and other libraries that support Arrow, like Pandas (under the hood with newer versions), PyArrow itself, and the rapidly growing Polars library.\n",
    "\n",
    "You can convert a DuckDB relation to an Arrow Table using `.arrow()` or `.fetcharrow()`, or the equivalent `.to_arrow_table()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyarrow.lib.Table'>\n",
      "pyarrow.Table\n",
      "Country: string\n",
      "Region: string\n",
      "----\n",
      "Country: [[\"Afghanistan \",\"Albania \",\"Algeria \",\"American Samoa \",\"Andorra \",\"Angola \",\"Anguilla \",\"Antigua & Barbuda \",\"Argentina \",\"Armenia \"]]\n",
      "Region: [[\"ASIA (EX. NEAR EAST)         \",\"EASTERN EUROPE                     \",\"NORTHERN AFRICA                    \",\"OCEANIA                            \",\"WESTERN EUROPE                     \",\"SUB-SAHARAN AFRICA                 \",\"LATIN AMER. & CARIB    \",\"LATIN AMER. & CARIB    \",\"LATIN AMER. & CARIB    \",\"C.W. OF IND. STATES \"]]\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pyarrow as pa\n",
    "# Make sure you have pyarrow installed: pip install pyarrow\n",
    "\n",
    "# Connect to DuckDB (or reuse connection)\n",
    "con = duckdb.connect(database=':memory:')\n",
    "con.sql(\"INSTALL httpfs\")\n",
    "con.sql(\"LOAD httpfs\")\n",
    "\n",
    "# Get a relation (from a file, table, or query)\n",
    "countries_relation = con.sql(\"SELECT Country, Region FROM read_csv_auto('https://bit.ly/3KoiZR0') LIMIT 10\")\n",
    "\n",
    "# Convert to an Apache Arrow Table\n",
    "arrow_table = countries_relation.arrow().read_all()\n",
    "\n",
    "print(type(arrow_table))\n",
    "\n",
    "print(arrow_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, converting to a Polars DataFrame is just as easy with `.pl()` (requires the `polars` library installed: `pip install polars`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'polars.dataframe.frame.DataFrame'>\n",
      "shape: (10, 2)\n",
      "┌────────────────────┬─────────────────────────────────┐\n",
      "│ Country            ┆ Region                          │\n",
      "│ ---                ┆ ---                             │\n",
      "│ str                ┆ str                             │\n",
      "╞════════════════════╪═════════════════════════════════╡\n",
      "│ Afghanistan        ┆ ASIA (EX. NEAR EAST)            │\n",
      "│ Albania            ┆ EASTERN EUROPE                … │\n",
      "│ Algeria            ┆ NORTHERN AFRICA               … │\n",
      "│ American Samoa     ┆ OCEANIA                       … │\n",
      "│ Andorra            ┆ WESTERN EUROPE                … │\n",
      "│ Angola             ┆ SUB-SAHARAN AFRICA            … │\n",
      "│ Anguilla           ┆ LATIN AMER. & CARIB             │\n",
      "│ Antigua & Barbuda  ┆ LATIN AMER. & CARIB             │\n",
      "│ Argentina          ┆ LATIN AMER. & CARIB             │\n",
      "│ Armenia            ┆ C.W. OF IND. STATES             │\n",
      "└────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "\n",
    "# Connect to DuckDB (or reuse connection)\n",
    "con = duckdb.connect(database=':memory:')\n",
    "con.sql(\"INSTALL httpfs\")\n",
    "con.sql(\"LOAD httpfs\")\n",
    "\n",
    "# Get a relation\n",
    "countries_relation = con.sql(\"SELECT Country, Region FROM read_csv_auto('https://bit.ly/3KoiZR0') LIMIT 10\")\n",
    "\n",
    "# Convert to a Polars DataFrame\n",
    "polars_df = countries_relation.pl()\n",
    "\n",
    "print(type(polars_df))\n",
    "\n",
    "print(polars_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Info: Deferring Materialization**\n",
    "> \n",
    "> Converting a DuckDB relation to a Python DataFrame/Table (`.df()`, `.arrow()`, `.pl()`) materializes the entire result set in Python memory. For performance, it's generally recommended that you perform as many filtering, projection, aggregation, and joining steps as possible using DuckDB's SQL or Relational API *before* converting to a Python object. This allows DuckDB's optimized query engine to process the data efficiently, often without bringing everything into Python memory until the final result is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have data as an Arrow table, you can use `pyarrow.compute` for further operations directly within Arrow if needed, though DuckDB often remains faster for many analytical queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and Selected Arrow Table:\n",
      "pyarrow.Table\n",
      "Country: string\n",
      "Region: string\n",
      "----\n",
      "Country: [[\"American Samoa \"]]\n",
      "Region: [[\"OCEANIA                            \"]]\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.compute as pc\n",
    "import pyarrow as pa\n",
    "\n",
    "# Convert RecordBatchReader to Table\n",
    "arrow_table = arrow_table.read_all()\n",
    "\n",
    "# Now you can use filter and select\n",
    "filtered_arrow = arrow_table.filter(pc.match_substring(arrow_table['Country'], 'America'))\n",
    "selected_arrow = filtered_arrow.select(['Country', 'Region'])\n",
    "\n",
    "print(\"Filtered and Selected Arrow Table:\")\n",
    "print(selected_arrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interoperability makes DuckDB a fantastic glue layer for data pipelines involving various Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending DuckDB with Python: User-Defined Functions (UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning: UDFs and MotherDuck**\n",
    "> \n",
    "> Please note that User-Defined Functions (UDFs), as described in this section, are a feature of the local, embedded DuckDB Python library and **do not work on MotherDuck**. The reason is that UDFs require a Python runtime to execute the function's code. MotherDuck is a serverless platform that provides SQL execution but does not run user-provided Python code on its servers. The examples below are for local DuckDB usage within a Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you need to perform an operation within your SQL query that's simply not available in standard SQL or DuckDB's built-in functions, but it's easy to do in Python. This is where User-Defined Functions (UDFs) come in. DuckDB lets you define Python functions and call them directly from your SQL queries.\n",
    "\n",
    "Let's revisit the population data. Looking at the `Region` column, there seem to be some extra spaces (padding) that make grouping or filtering tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading population data from URL...\n",
      "Population data loaded.\n",
      "┌─────────────────────────────────────┬──────────┐\n",
      "│               Region                │ numChars │\n",
      "│               varchar               │  int64   │\n",
      "├─────────────────────────────────────┼──────────┤\n",
      "│ NEAR EAST                           │       35 │\n",
      "│ LATIN AMER. & CARIB                 │       23 │\n",
      "│ WESTERN EUROPE                      │       35 │\n",
      "│ SUB-SAHARAN AFRICA                  │       35 │\n",
      "│ NORTHERN AFRICA                     │       35 │\n",
      "│ EASTERN EUROPE                      │       35 │\n",
      "│ OCEANIA                             │       35 │\n",
      "│ NORTHERN AMERICA                    │       35 │\n",
      "│ C.W. OF IND. STATES                 │       20 │\n",
      "│ BALTICS                             │       35 │\n",
      "│ ASIA (EX. NEAR EAST)                │       29 │\n",
      "├─────────────────────────────────────┴──────────┤\n",
      "│ 11 rows                              2 columns │\n",
      "└────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to DuckDB and load population data\n",
    "con = duckdb.connect(database=':memory:') # Or use the persistent DB file\n",
    "con.sql(\"INSTALL httpfs\")\n",
    "con.sql(\"LOAD httpfs\")\n",
    "# Load the data into a table if it doesn't exist in this session\n",
    "try:\n",
    "    con.sql(\"SELECT COUNT(*) FROM population\")\n",
    "except duckdb.CatalogException:\n",
    "    print(\"Loading population data from URL...\")\n",
    "    con.sql(\"SELECT * FROM read_csv_auto('https://bit.ly/3KoiZR0')\").to_table(\"population\")\n",
    "    print(\"Population data loaded.\")\n",
    "\n",
    "\n",
    "con.sql(\"\"\"\n",
    "SELECT DISTINCT Region, length(Region) AS numChars\n",
    "FROM population\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See those character counts? 23 for \"LATIN AMER. & CARIB\" looks about right, but 35 for \"BALTICS\" (which is 7 characters long)? Definitely trailing spaces.\n",
    "\n",
    "DuckDB has a built-in `trim()` function, but for the sake of demonstration, you can write a Python UDF to remove leading/trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x11c157830>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_spaces_py(field: str) -> str:\n",
    "    \"\"\"Removes leading/trailing spaces from a string.\"\"\"\n",
    "    if field is not None:\n",
    "        # Use Python's strip()\n",
    "        return field.strip() # Python's strip() removes both leading/trailing\n",
    "        # Or use lstrip() and rstrip() specifically\n",
    "        # return field.lstrip().rstrip()\n",
    "    return field\n",
    "\n",
    "# Register the Python function as a SQL function in DuckDB\n",
    "con.create_function('remove_spaces_py', remove_spaces_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You defined a simple Python function `remove_spaces_py`. You used type hints (`str` for input and output), which helps DuckDB infer the SQL types (VARCHAR). Then, `con.create_function()` registers this Python function under a name you can use in SQL (`remove_spaces_py`).\n",
    "\n",
    "### Introspecting Registered Functions\n",
    "\n",
    "After registering a UDF, you can query DuckDB's built-in `duckdb_functions()` table function to see information about all available functions, including your new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬───────────────┬────────────┬─────────────────┬─────────────┐\n",
      "│  function_name   │ function_type │ parameters │ parameter_types │ return_type │\n",
      "│     varchar      │    varchar    │ varchar[]  │    varchar[]    │   varchar   │\n",
      "├──────────────────┼───────────────┼────────────┼─────────────────┼─────────────┤\n",
      "│ remove_spaces_py │ scalar        │ [col0]     │ [VARCHAR]       │ VARCHAR     │\n",
      "└──────────────────┴───────────────┴────────────┴─────────────────┴─────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT function_name, function_type, parameters, parameter_types, return_type\n",
    "FROM duckdb_functions()\n",
    "WHERE function_name = 'remove_spaces_py'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This introspection confirms your function is registered correctly with the inferred types.\n",
    "\n",
    "Now, try using it in a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────┬───────┬──────────────────────┬───────┐\n",
      "│           original_region           │ len1  │    cleaned_region    │ len2  │\n",
      "│               varchar               │ int64 │       varchar        │ int64 │\n",
      "├─────────────────────────────────────┼───────┼──────────────────────┼───────┤\n",
      "│ ASIA (EX. NEAR EAST)                │    29 │ ASIA (EX. NEAR EAST) │    20 │\n",
      "│ EASTERN EUROPE                      │    35 │ EASTERN EUROPE       │    14 │\n",
      "│ NORTHERN AFRICA                     │    35 │ NORTHERN AFRICA      │    15 │\n",
      "└─────────────────────────────────────┴───────┴──────────────────────┴───────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "    Region AS original_region,\n",
    "    length(Region) AS len1,\n",
    "    remove_spaces_py(Region) AS cleaned_region,\n",
    "    length(remove_spaces_py(Region)) AS len2\n",
    "FROM population\n",
    "WHERE length(Region) > length(remove_spaces_py(Region)) -- Only show rows where trimming actually happened\n",
    "LIMIT 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Your Python UDF `remove_spaces_py` is correctly callable from SQL and does its job.\n",
    "\n",
    "DuckDB usually does a good job inferring types from Python type hints. However, for clarity or if type hints are missing, you can explicitly specify the input and return types when registering the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x11c157830>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from duckdb.sqltypes import VARCHAR\n",
    "\n",
    "# Remove the old function first (optional, but good practice if redefining)\n",
    "try:\n",
    "    con.remove_function('remove_spaces_py')\n",
    "except duckdb.InvalidInputException: # Function might not exist yet\n",
    "    pass\n",
    "\n",
    "\n",
    "# Register again, explicitly specifying types\n",
    "con.create_function(\n",
    "    'remove_spaces_py',\n",
    "    remove_spaces_py, # Use the Python function object\n",
    "    [VARCHAR],  # List of input types (a single VARCHAR parameter)\n",
    "    VARCHAR       # Return type (VARCHAR)\n",
    ")\n",
    "# Now you can use it just as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Data Cleaning: Handling Locale-Specific Decimals\n",
    "\n",
    "A common data cleaning task is handling numbers formatted according to different regional conventions, such as using a comma (`,`) as a decimal separator instead of a period (`.`). If ingested without proper handling, these numbers might be treated as strings.\n",
    "\n",
    "The population dataset you are using includes columns like `\"Coastline (coast/area ratio)\"` and `\"Pop. Density (per sq. mi.)\"` which appear to use the European comma format. You can define a Python UDF using the `locale` module to convert these strings to numeric types.\n",
    "\n",
    "First, make sure the `locale` module is available and you have a locale installed that uses comma as a decimal separator (like 'de_DE' for German). You might need to configure your operating system's locales if they aren't available by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x11c157830>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "from duckdb.sqltypes import DOUBLE, VARCHAR\n",
    "\n",
    "# Define the Python function to convert locale-specific strings to float\n",
    "def convert_locale_py(field: str) -> float:\n",
    "    \"\"\"Converts a locale-specific string (e.g., using comma decimal) to a float.\"\"\"\n",
    "    if field is None:\n",
    "        return None\n",
    "    try:\n",
    "        # Set locale temporarily (consider thread safety in multi-threaded apps)\n",
    "        # You might need to adjust the locale string based on your system setup\n",
    "        original_locale = locale.getlocale(locale.LC_NUMERIC)\n",
    "        # The locale string can vary. 'de_DE.UTF-8' is common on Linux.\n",
    "        # On Windows, it might be 'German_Germany.1252' or just 'de'.\n",
    "        # On MacOS, it might be 'de_DE.UTF-8'.\n",
    "        # We'll try a few common ones.\n",
    "        locales_to_try = ['de_DE.UTF-8', 'de_DE', 'de', 'German']\n",
    "        for loc in locales_to_try:\n",
    "            try:\n",
    "                locale.setlocale(locale.LC_NUMERIC, loc)\n",
    "                break\n",
    "            except locale.Error:\n",
    "                continue\n",
    "        else:\n",
    "             # If no locale worked, we can't do the conversion this way.\n",
    "             # A more robust solution might be a simple string replace.\n",
    "             return float(field.replace(',', '.'))\n",
    "\n",
    "        # Use locale.atof to convert string to float based on locale settings\n",
    "        result = locale.atof(field)\n",
    "        # Restore original locale\n",
    "        locale.setlocale(locale.LC_NUMERIC, original_locale)\n",
    "        return result\n",
    "    except (ValueError, TypeError):\n",
    "        return None # Return None for conversion errors\n",
    "\n",
    "# Register the function with DuckDB, specifying input and output types\n",
    "con.create_function(\n",
    "    'convert_locale_py',\n",
    "    convert_locale_py,\n",
    "    [VARCHAR], # Expecting a VARCHAR input\n",
    "    DOUBLE       # Returning a DOUBLE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Note: Handling locales can be system-dependent. The locale string `'de_DE.UTF-8'` might need adjustment. Setting and restoring the locale is important in applications to avoid side effects. The code above includes fallback logic for robustness.)*\n",
    "\n",
    "Now, use your `convert_locale_py` function in a query to see how it transforms the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────┬──────────────────────────┬──────────────────────┬────────────────────────────┐\n",
      "│ original_coastline │ cleaned_coastline_double │ original_pop_density │ cleaned_pop_density_double │\n",
      "│      varchar       │          double          │       varchar        │           double           │\n",
      "├────────────────────┼──────────────────────────┼──────────────────────┼────────────────────────────┤\n",
      "│ 0,00               │                      0.0 │ 48,0                 │                       48.0 │\n",
      "│ 1,26               │                     1.26 │ 124,6                │                      124.6 │\n",
      "│ 0,04               │                     0.04 │ 13,8                 │                       13.8 │\n",
      "│ 58,29              │                    58.29 │ 290,4                │                      290.4 │\n",
      "│ 0,00               │                      0.0 │ 152,1                │                      152.1 │\n",
      "└────────────────────┴──────────────────────────┴──────────────────────┴────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con.sql(\"\"\"\n",
    "SELECT\n",
    "    \"Coastline (coast/area ratio)\" AS original_coastline,\n",
    "    convert_locale_py(\"Coastline (coast/area ratio)\") AS cleaned_coastline_double,\n",
    "    \"Pop. Density (per sq. mi.)\" AS original_pop_density,\n",
    "    convert_locale_py(\"Pop. Density (per sq. mi.)\") AS cleaned_pop_density_double\n",
    "FROM population\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! The UDF successfully converted the comma-separated strings to standard double-precision floating-point numbers.\n",
    "\n",
    "This UDF capability opens the door to using any Python library within your SQL queries, from complex string manipulations with `re` to mathematical functions with `numpy` or `scipy`, or even calling external APIs (though be mindful of performance implications for row-by-row processing).\n",
    "\n",
    "Once you've verified the conversion, you can use `ALTER TABLE` to change the column's data type permanently and apply the UDF to update the values in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────────────────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐\n",
      "│            column_name             │ column_type │  null   │   key   │ default │  extra  │\n",
      "│              varchar               │   varchar   │ varchar │ varchar │ varchar │ varchar │\n",
      "├────────────────────────────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤\n",
      "│ Country                            │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Region                             │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Population                         │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Area (sq. mi.)                     │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Pop. Density (per sq. mi.)         │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Coastline (coast/area ratio)       │ DOUBLE      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Net migration                      │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Infant mortality (per 1000 births) │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ GDP ($ per capita)                 │ BIGINT      │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Literacy (%)                       │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Phones (per 1000)                  │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Arable (%)                         │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Crops (%)                          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Other (%)                          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Climate                            │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Birthrate                          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Deathrate                          │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Agriculture                        │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Industry                           │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "│ Service                            │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │\n",
      "├────────────────────────────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┤\n",
      "│ 20 rows                                                                        6 columns │\n",
      "└──────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con.sql(\"\"\"\n",
    "ALTER TABLE population\n",
    "ALTER \"Coastline (coast/area ratio)\"\n",
    "SET DATA TYPE DOUBLE\n",
    "USING convert_locale_py(\"Coastline (coast/area ratio)\")\n",
    "\"\"\")\n",
    "\n",
    "con.sql(\"\"\"\n",
    "ALTER TABLE population\n",
    "ALTER \"Pop. Density (per sq. mi.)\"\n",
    "SET DATA TYPE DOUBLE\n",
    "USING convert_locale_py(\"Pop. Density (per sq. mi.)\")\n",
    "\"\"\")\n",
    "\n",
    "# You would repeat this for other columns needing locale conversion like\n",
    "# \"Birthrate\", \"Deathrate\" etc.\n",
    "\n",
    "# Verify the column type change\n",
    "con.sql(\"DESCRIBE population\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Info: UDF Performance Considerations**\n",
    "> \n",
    "> While Python UDFs are incredibly flexible, they typically execute row-by-row and involve context switching between DuckDB's C++ execution engine and the Python interpreter. This can be slower than DuckDB's highly optimized vectorized native functions. You should use UDFs when a necessary operation *cannot* be done efficiently or at all in SQL, but prefer native SQL functions (`trim()`, `replace()`, etc.) for common tasks when available. For the locale conversion, using a UDF might be necessary if a suitable built-in function or reader option isn't available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Time\n",
    "\n",
    "When you're finished with a persistent database connection, it's good practice to close it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures any pending writes are flushed and resources are released. For in-memory databases created with `:memory:` or the default `duckdb.sql()` connection, this isn't strictly necessary as they live and die with the Python process or script execution, but it doesn't hurt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "\n",
    "This two-part DuckDB Python quickstart has covered the essential features that make DuckDB such a powerful tool for data engineers, analysts, and scientists. Its embedded nature eliminates the overhead of managing a separate database server for local work. Its columnar architecture and vectorized execution make analytical queries on large datasets surprisingly fast.\n",
    "\n",
    "But perhaps its biggest win is the deep integration with the Python data ecosystem. The ability to query Pandas DataFrames directly, seamlessly convert results to and from DataFrames, and leverage Arrow for efficient data transfer makes DuckDB feel like a natural extension of your Python data stack. The Relational API provides a robust, programmatic way to build queries, complementing standard SQL and enabling safer, more maintainable code. Add in the flexibility of Python UDFs for tackling custom cleaning and transformation tasks, and you have a powerful, high-performance tool that fits snugly into modern data workflows.\n",
    "\n",
    "So next time you're faced with a pile of data files or a large DataFrame and need to slice and dice it with SQL or relational operations, don't groan about setting up a server. Just remember this DuckDB Python quickstart guide, and get quacking on your analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
